[
  {
    "id": "ace-compute-001",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "Your company needs to deploy a web application that processes batch jobs. The workload can tolerate interruptions and needs to minimize costs.",
    "question": "What should you do to minimize costs while maintaining the ability to process the workload?",
    "options": [
      {
        "id": "A",
        "text": "Use Compute Engine instances with sustained use discounts"
      },
      {
        "id": "B",
        "text": "Deploy to App Engine with automatic scaling enabled"
      },
      {
        "id": "C",
        "text": "Use preemptible VMs with a managed instance group"
      },
      {
        "id": "D",
        "text": "Deploy to Google Kubernetes Engine with node autoscaling"
      }
    ],
    "correctAnswer": ["C"],
    "explanation": {
      "correct": "Preemptible VMs cost up to 80% less than regular instances and are ideal for batch processing and fault-tolerant workloads that can handle interruptions. Using a managed instance group provides automatic recovery if instances are preempted.",
      "incorrect": {
        "A": "While sustained use discounts reduce costs, they don't provide the 80% savings that preemptible VMs offer for fault-tolerant workloads.",
        "B": "App Engine is more expensive for compute-intensive batch jobs and doesn't provide the same cost optimization as preemptible VMs.",
        "D": "GKE adds orchestration overhead and complexity. For simple batch processing, managed instance groups with preemptible VMs are more cost-effective."
      }
    },
    "keyConceptName": "Cost Optimization - Preemptible VMs",
    "keyConcept": "Preemptible VMs are Google-recommended for fault-tolerant, batch processing workloads that can handle interruptions. They provide up to 80% cost savings compared to regular instances.",
    "tags": [
      "preemptible-vms",
      "cost-optimization",
      "batch-processing",
      "managed-instance-groups"
    ],
    "examPatternKeywords": ["minimize cost", "fault-tolerant", "interruptions"],
    "relatedQuestionIds": ["ace-compute-015", "ace-compute-032"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instances/preemptible"
  },
  {
    "id": "ace-compute-002",
    "domain": "compute-engine",
    "difficulty": "hard",
    "type": "multiple-select",
    "scenario": "You are setting up a highly available web application that needs to handle variable traffic and automatically recover from failures.",
    "question": "Which components should you use to achieve high availability and automatic recovery? (Select 3)",
    "options": [
      {
        "id": "A",
        "text": "Instance templates to define VM configuration"
      },
      {
        "id": "B",
        "text": "Regional managed instance groups for distribution"
      },
      {
        "id": "C",
        "text": "Single-zone persistent disks for data storage"
      },
      {
        "id": "D",
        "text": "Health checks with autohealing enabled"
      },
      {
        "id": "E",
        "text": "Manual scaling to control costs"
      }
    ],
    "correctAnswer": ["A", "B", "D"],
    "explanation": {
      "correct": "Instance templates define consistent VM configurations, regional managed instance groups distribute instances across multiple zones for high availability, and health checks with autohealing automatically replace failed instances.",
      "incorrect": {
        "C": "Single-zone persistent disks create a single point of failure. For high availability, use regional persistent disks or replicate data across zones.",
        "E": "Manual scaling doesn't provide automatic recovery or handle variable traffic automatically. Autoscaling is needed for high availability."
      }
    },
    "keyConceptName": "High Availability Architecture",
    "keyConcept": "High availability requires: (1) Instance templates for consistency, (2) Regional managed instance groups for multi-zone distribution, (3) Health checks with autohealing for automatic recovery, and (4) Autoscaling for variable traffic.",
    "tags": [
      "high-availability",
      "managed-instance-groups",
      "autohealing",
      "instance-templates"
    ],
    "examPatternKeywords": [
      "high availability",
      "automatic recovery",
      "google-recommended"
    ],
    "relatedQuestionIds": ["ace-compute-005", "ace-compute-018"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instance-groups"
  },
  {
    "id": "ace-compute-003",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "You have a Managed Instance Group (MIG) running web servers. During deployment of a new instance template, you want to ensure zero downtime and that capacity never drops below current levels.",
    "question": "Which rolling update configuration should you use?",
    "options": [
      {
        "id": "A",
        "text": "Set maxSurge to 0 and maxUnavailable to 1"
      },
      {
        "id": "B",
        "text": "Set maxSurge to 1 and maxUnavailable to 0"
      },
      {
        "id": "C",
        "text": "Set maxSurge to 1 and maxUnavailable to 1"
      },
      {
        "id": "D",
        "text": "Set maxSurge to 0 and maxUnavailable to 0"
      }
    ],
    "correctAnswer": ["B"],
    "explanation": {
      "correct": "maxSurge=1 allows creating additional instances before removing old ones, and maxUnavailable=0 ensures no instances are taken down during the update. This maintains or increases capacity throughout the deployment, ensuring zero downtime.",
      "incorrect": {
        "A": "maxUnavailable=1 means instances will be terminated before new ones are ready, temporarily reducing capacity and potentially causing downtime.",
        "C": "While this works, allowing maxUnavailable=1 can temporarily reduce capacity, which violates the requirement to never drop below current levels.",
        "D": "Both set to 0 would prevent any updates from occurring, as no instances can be created or removed."
      }
    },
    "keyConceptName": "Managed Instance Group Rolling Updates",
    "keyConcept": "MIG rolling updates use maxSurge (extra instances during update) and maxUnavailable (instances that can be down) to control update behavior. For zero downtime and maintained capacity, use maxSurge > 0 and maxUnavailable = 0.",
    "tags": [
      "compute-engine",
      "managed-instance-group",
      "rolling-updates",
      "zero-downtime"
    ],
    "examPatternKeywords": [
      "zero downtime",
      "capacity never drops",
      "deployment"
    ],
    "relatedQuestionIds": ["ace-compute-004", "ace-compute-007"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instance-groups/rolling-out-updates-to-managed-instance-groups"
  },
  {
    "id": "ace-compute-004",
    "domain": "compute-engine",
    "difficulty": "hard",
    "type": "multiple-select",
    "scenario": "Your application runs on a Managed Instance Group with autoscaling enabled. Instances take 3 minutes to fully initialize and start serving traffic. You're seeing instances being added and removed too frequently. What should you configure? (Select 3)",
    "question": "Which configurations will stabilize the autoscaling behavior?",
    "options": [
      {
        "id": "A",
        "text": "Increase the health check initial delay to 200 seconds"
      },
      {
        "id": "B",
        "text": "Configure cooldown period to allow stabilization after scaling"
      },
      {
        "id": "C",
        "text": "Set a higher CPU utilization target (e.g., 80% instead of 60%)"
      },
      {
        "id": "D",
        "text": "Enable predictive autoscaling for better forecasting"
      },
      {
        "id": "E",
        "text": "Decrease the health check interval to 5 seconds"
      }
    ],
    "correctAnswer": ["A", "B", "D"],
    "explanation": {
      "correct": "Increasing initial delay (A) prevents premature health check failures during initialization, cooldown periods (B) prevent thrashing by waiting after scale events, and predictive autoscaling (D) anticipates demand to scale proactively and smoothly.",
      "incorrect": {
        "C": "Increasing CPU target may reduce scaling frequency but could impact performance. It doesn't address the root causes of instability.",
        "E": "Decreasing health check interval makes the system more reactive and could increase instability, especially during the 3-minute initialization period."
      }
    },
    "keyConceptName": "Autoscaling Stability Configuration",
    "keyConcept": "Stable autoscaling requires proper health check timing (initial delay matching startup time), cooldown periods between scaling events, and optionally predictive autoscaling. These prevent oscillation and premature scaling decisions.",
    "tags": ["compute-engine", "autoscaling", "health-checks", "stability"],
    "examPatternKeywords": [
      "too frequently",
      "stabilize",
      "initialization time"
    ],
    "relatedQuestionIds": ["ace-compute-003", "ace-compute-011"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/autoscaler"
  },
  {
    "id": "ace-compute-005",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "You need to run a batch processing job that takes 8 hours to complete. The job can tolerate interruptions and can restart from checkpoints. You want to minimize costs.",
    "question": "Which instance type should you use?",
    "options": [
      {
        "id": "A",
        "text": "Standard instances with committed use discounts"
      },
      {
        "id": "B",
        "text": "Preemptible VM instances"
      },
      {
        "id": "C",
        "text": "Spot VM instances"
      },
      {
        "id": "D",
        "text": "Standard instances in a Managed Instance Group"
      }
    ],
    "correctAnswer": ["C"],
    "explanation": {
      "correct": "Spot VMs are the evolution of Preemptible VMs with better pricing and no maximum runtime. Since the job is fault-tolerant with checkpointing, Spot VMs offer the lowest cost (up to 91% discount) and can run for longer than 24 hours if capacity is available.",
      "incorrect": {
        "A": "Committed use discounts save money but still cost significantly more than Spot VMs. For fault-tolerant workloads, Spot VMs are more cost-effective.",
        "B": "Preemptible VMs have a maximum runtime of 24 hours and will always be terminated after 24 hours. Spot VMs are the newer, better option.",
        "D": "Standard instances in a MIG provide high availability but don't offer the cost savings needed for batch processing workloads."
      }
    },
    "keyConceptName": "Spot VMs for Batch Processing",
    "keyConcept": "Spot VMs (successor to Preemptible VMs) offer up to 91% cost savings for fault-tolerant workloads. They have no maximum runtime and are ideal for batch jobs, data processing, and any interruptible workload with checkpointing.",
    "tags": [
      "compute-engine",
      "spot-vms",
      "cost-optimization",
      "batch-processing"
    ],
    "examPatternKeywords": [
      "minimize costs",
      "tolerates interruptions",
      "batch processing"
    ],
    "relatedQuestionIds": ["ace-compute-006", "ace-compute-012"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instances/spot"
  },
  {
    "id": "ace-compute-006",
    "domain": "compute-engine",
    "difficulty": "easy",
    "type": "multiple-choice",
    "scenario": "You have a VM instance that requires 4 vCPUs and 32 GB of memory for your application. No predefined machine type matches these requirements exactly.",
    "question": "What should you do?",
    "options": [
      {
        "id": "A",
        "text": "Use the n1-standard-4 machine type which has 4 vCPUs but only 15 GB memory"
      },
      {
        "id": "B",
        "text": "Create a custom machine type with 4 vCPUs and 32 GB memory"
      },
      {
        "id": "C",
        "text": "Use the n1-highmem-4 machine type which has 4 vCPUs and 26 GB memory"
      },
      {
        "id": "D",
        "text": "Use the n1-standard-8 machine type and pay for unused vCPUs"
      }
    ],
    "correctAnswer": ["B"],
    "explanation": {
      "correct": "Custom machine types allow you to specify exact vCPU and memory requirements. This is the most cost-effective option when predefined types don't match your needs, as you only pay for what you use.",
      "incorrect": {
        "A": "15 GB is insufficient for the application's 32 GB memory requirement. The application would likely fail or perform poorly.",
        "C": "26 GB is less than the required 32 GB. While closer, it still doesn't meet the application's memory requirements.",
        "D": "Using a larger machine type wastes resources and money. Custom machine types provide better cost optimization."
      }
    },
    "keyConceptName": "Custom Machine Types",
    "keyConcept": "Custom machine types let you create VMs with specific vCPU and memory configurations when predefined types don't match your needs. This optimizes costs by paying only for required resources, with vCPU-to-memory ratios from 0.9 GB to 6.5 GB per vCPU.",
    "tags": [
      "compute-engine",
      "custom-machine-types",
      "cost-optimization",
      "sizing"
    ],
    "examPatternKeywords": [
      "exact requirements",
      "no predefined",
      "specific configuration"
    ],
    "relatedQuestionIds": ["ace-compute-013", "ace-compute-014"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type"
  },
  {
    "id": "ace-compute-007",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "Your Managed Instance Group needs to maintain at least 5 instances running at all times for high availability, even during maintenance events. You want instances to automatically restart if they crash.",
    "question": "What should you configure in the instance template?",
    "options": [
      {
        "id": "A",
        "text": "Set automatic restart to ON and on-host maintenance to TERMINATE"
      },
      {
        "id": "B",
        "text": "Set automatic restart to ON and on-host maintenance to MIGRATE"
      },
      {
        "id": "C",
        "text": "Set automatic restart to OFF and on-host maintenance to MIGRATE"
      },
      {
        "id": "D",
        "text": "Configure autohealing with health checks"
      }
    ],
    "correctAnswer": ["B"],
    "explanation": {
      "correct": "Automatic restart ON ensures instances restart after crashes. On-host maintenance MIGRATE ensures instances are live-migrated during GCP maintenance, maintaining availability without downtime. This combination provides maximum uptime.",
      "incorrect": {
        "A": "TERMINATE during maintenance means instances are stopped and restarted on new hosts, causing temporary unavailability during GCP maintenance events.",
        "C": "Automatic restart OFF means instances won't restart after crashes, violating the availability requirement.",
        "D": "While autohealing is good practice, it doesn't specifically address automatic restart on crashes or behavior during host maintenance events."
      }
    },
    "keyConceptName": "Instance Availability Configuration",
    "keyConcept": "Configure automatic restart (ON) for crash recovery and on-host maintenance (MIGRATE) for live migration during GCP maintenance. This combination maximizes uptime. Use with MIGs and health checks for comprehensive high availability.",
    "tags": [
      "compute-engine",
      "high-availability",
      "instance-template",
      "maintenance"
    ],
    "examPatternKeywords": [
      "at all times",
      "high availability",
      "automatically restart"
    ],
    "relatedQuestionIds": ["ace-compute-003", "ace-compute-011"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instances/setting-instance-scheduling-options"
  },
  {
    "id": "ace-compute-008",
    "domain": "compute-engine",
    "difficulty": "hard",
    "type": "multiple-choice",
    "scenario": "Your application needs GPU acceleration for machine learning workloads. The workloads run for 6-12 hours and can checkpoint progress. You need to minimize costs while using GPUs.",
    "question": "What instance configuration should you use?",
    "options": [
      {
        "id": "A",
        "text": "Standard instances with attached GPUs and committed use discounts"
      },
      {
        "id": "B",
        "text": "Preemptible instances with attached GPUs"
      },
      {
        "id": "C",
        "text": "Spot instances with attached GPUs"
      },
      {
        "id": "D",
        "text": "Standard instances with attached GPUs in a Managed Instance Group"
      }
    ],
    "correctAnswer": ["C"],
    "explanation": {
      "correct": "Spot instances with GPUs offer the lowest cost (up to 91% discount). Since workloads can checkpoint and recovery from interruption, and Spot VMs don't have the 24-hour maximum runtime limit of Preemptible VMs, they're ideal for 6-12 hour ML workloads.",
      "incorrect": {
        "A": "Committed use discounts help but don't provide the dramatic savings of Spot VMs for interruptible workloads.",
        "B": "Preemptible VMs have a 24-hour maximum runtime, which is fine for this workload, but Spot VMs are the newer, recommended option with better pricing.",
        "D": "MIGs with standard instances provide high availability but at significantly higher cost. For batch ML workloads with checkpointing, this is unnecessary."
      }
    },
    "keyConceptName": "GPU Cost Optimization",
    "keyConcept": "Combine GPUs with Spot VMs for significant cost savings on fault-tolerant ML workloads. GPUs are available on Spot instances, offering the same 91% discount as CPU-only Spot VMs. Implement checkpointing to handle interruptions.",
    "tags": [
      "compute-engine",
      "gpu",
      "spot-vms",
      "machine-learning",
      "cost-optimization"
    ],
    "examPatternKeywords": ["GPU", "minimize costs", "checkpoint"],
    "relatedQuestionIds": ["ace-compute-005", "ace-gke-009"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/gpus"
  },
  {
    "id": "ace-compute-009",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "You need to grant a Compute Engine instance access to read objects from a Cloud Storage bucket. You want to follow Google-recommended security practices without using service account keys.",
    "question": "What should you do?",
    "options": [
      {
        "id": "A",
        "text": "Download a service account key and store it on the instance"
      },
      {
        "id": "B",
        "text": "Create a custom service account with Storage Object Viewer role and attach it to the instance"
      },
      {
        "id": "C",
        "text": "Use the default Compute Engine service account with Editor role"
      },
      {
        "id": "D",
        "text": "Configure access scopes to allow Cloud Storage read access"
      }
    ],
    "correctAnswer": ["B"],
    "explanation": {
      "correct": "Create a custom service account with minimal permissions (Storage Object Viewer) and attach it to the instance. This follows least privilege and uses workload identity, avoiding keys entirely. The instance automatically authenticates using the attached service account.",
      "incorrect": {
        "A": "Service account keys should be avoided whenever possible. They present security risks if compromised. Attached service accounts eliminate the need for keys.",
        "C": "The default service account with Editor role violates the principle of least privilege. Always create custom service accounts with minimal required permissions.",
        "D": "Access scopes are a legacy mechanism and less flexible than IAM roles. Modern best practice is to use IAM roles on custom service accounts."
      }
    },
    "keyConceptName": "Compute Engine Service Account Best Practices",
    "keyConcept": "Attach custom service accounts with minimal IAM permissions to instances. Never use service account keys when workload identity is available. Avoid default service accounts and overly broad permissions like Editor role.",
    "tags": [
      "compute-engine",
      "service-accounts",
      "iam",
      "least-privilege",
      "security"
    ],
    "examPatternKeywords": [
      "google-recommended",
      "without keys",
      "security practices"
    ],
    "relatedQuestionIds": ["ace-iam-002", "ace-compute-010"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/access/create-enable-service-accounts-for-instances"
  },
  {
    "id": "ace-compute-010",
    "domain": "compute-engine",
    "difficulty": "easy",
    "type": "multiple-choice",
    "scenario": "You need to create snapshots of a persistent disk attached to a production VM. You want to minimize the impact on the running application.",
    "question": "What is the recommended approach?",
    "options": [
      {
        "id": "A",
        "text": "Stop the instance, create the snapshot, then restart the instance"
      },
      {
        "id": "B",
        "text": "Create a snapshot while the instance is running"
      },
      {
        "id": "C",
        "text": "Detach the disk, create the snapshot, then reattach"
      },
      {
        "id": "D",
        "text": "Use gcloud to export the disk to Cloud Storage first"
      }
    ],
    "correctAnswer": ["B"],
    "explanation": {
      "correct": "Persistent disk snapshots can be created while instances are running without stopping them. GCP uses copy-on-write technology to create consistent snapshots with minimal performance impact. This is the recommended approach for production systems.",
      "incorrect": {
        "A": "Stopping the instance causes unnecessary downtime. Snapshots can be created from running instances safely.",
        "C": "Detaching disks requires stopping the instance (for boot disks) or significantly impacts the application. This is unnecessary and causes downtime.",
        "D": "Export is different from snapshot and is used for moving disks between projects/zones. Snapshots are simpler and don't require export to Cloud Storage."
      }
    },
    "keyConceptName": "Persistent Disk Snapshots",
    "keyConcept": "Create snapshots of persistent disks while instances are running. GCP ensures consistency using copy-on-write. Snapshots are incremental, compressed, and stored globally. Use snapshot schedules for automated backups.",
    "tags": ["compute-engine", "snapshots", "backup", "persistent-disk"],
    "examPatternKeywords": [
      "minimize impact",
      "running application",
      "production"
    ],
    "relatedQuestionIds": ["ace-compute-011", "ace-storage-004"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/disks/snapshots"
  },
  {
    "id": "ace-compute-011",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "Your Managed Instance Group serves web traffic behind a load balancer. Some instances occasionally become unresponsive but don't crash. You want unhealthy instances to be automatically replaced.",
    "question": "What should you configure?",
    "options": [
      {
        "id": "A",
        "text": "Enable automatic restart on the instance template"
      },
      {
        "id": "B",
        "text": "Configure autohealing with an HTTP health check"
      },
      {
        "id": "C",
        "text": "Set up a Cloud Monitoring alert to notify operators"
      },
      {
        "id": "D",
        "text": "Increase the health check interval to detect failures faster"
      }
    ],
    "correctAnswer": ["B"],
    "explanation": {
      "correct": "Autohealing with health checks monitors application-level health (not just VM-level) and automatically recreates unhealthy instances. HTTP health checks verify the application is responding correctly, catching unresponsive instances that haven't crashed.",
      "incorrect": {
        "A": "Automatic restart only helps when instances crash completely. It doesn't detect or fix unresponsive applications that are still running.",
        "C": "Alerts notify operators but don't automatically resolve the issue. Autohealing provides automatic remediation.",
        "D": "Decreasing (not increasing) the interval detects failures faster, but without autohealing configured, detection alone doesn't trigger replacement."
      }
    },
    "keyConceptName": "Managed Instance Group Autohealing",
    "keyConcept": "Autohealing automatically recreates unhealthy instances based on health check results. Configure application-level health checks (HTTP/HTTPS) to detect unresponsive applications, not just VM failures. Set appropriate initial delay to avoid false positives during startup.",
    "tags": [
      "compute-engine",
      "autohealing",
      "health-checks",
      "managed-instance-group"
    ],
    "examPatternKeywords": [
      "automatically replaced",
      "unresponsive",
      "don't crash"
    ],
    "relatedQuestionIds": ["ace-compute-004", "ace-compute-007"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instance-groups/autohealing-instances-in-migs"
  },
  {
    "id": "ace-compute-012",
    "domain": "compute-engine",
    "difficulty": "hard",
    "type": "multiple-select",
    "scenario": "You're designing a high-performance computing cluster on Compute Engine that requires low-latency networking between instances and fast local storage for temporary data. What should you configure? (Select 3)",
    "question": "Which features will optimize performance for this HPC workload?",
    "options": [
      {
        "id": "A",
        "text": "Place instances in a single placement group with compact placement policy"
      },
      {
        "id": "B",
        "text": "Attach local SSD disks to each instance"
      },
      {
        "id": "C",
        "text": "Use C2 or C3 machine types optimized for compute-intensive workloads"
      },
      {
        "id": "D",
        "text": "Enable live migration for maintenance"
      },
      {
        "id": "E",
        "text": "Use regional persistent disks for shared storage"
      }
    ],
    "correctAnswer": ["A", "B", "C"],
    "explanation": {
      "correct": "Compact placement groups (A) minimize network latency by placing instances physically close together. Local SSDs (B) provide the highest IOPS and lowest latency for temporary data. C2/C3 machine types (C) are optimized for compute-intensive HPC workloads.",
      "incorrect": {
        "D": "Live migration can temporarily impact network performance. HPC workloads often disable it in favor of termination during maintenance for consistent performance.",
        "E": "Regional persistent disks have higher latency than local SSDs. For temporary HPC data requiring maximum performance, local SSDs are preferred."
      }
    },
    "keyConceptName": "High-Performance Computing on Compute Engine",
    "keyConcept": "Optimize HPC workloads using compact placement groups for low-latency networking, local SSDs for high-IOPS storage, and compute-optimized machine types. Consider disabling live migration for consistent performance.",
    "tags": [
      "compute-engine",
      "hpc",
      "placement-groups",
      "local-ssd",
      "performance"
    ],
    "examPatternKeywords": [
      "low-latency",
      "high-performance",
      "fast local storage"
    ],
    "relatedQuestionIds": ["ace-compute-006", "ace-storage-007"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instances/use-compact-placement-policies"
  },
  {
    "id": "ace-compute-013",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "Your VM instance needs additional CPU capacity during business hours (9 AM - 6 PM) but can run with minimal resources during off-hours. You want to optimize costs.",
    "question": "What approach should you take?",
    "options": [
      {
        "id": "A",
        "text": "Use a larger instance type with committed use discounts"
      },
      {
        "id": "B",
        "text": "Create two instance templates and use Cloud Scheduler to swap between them"
      },
      {
        "id": "C",
        "text": "Resize the instance using gcloud compute instances set-machine-type during off-hours"
      },
      {
        "id": "D",
        "text": "Use a Managed Instance Group with scheduled autoscaling"
      }
    ],
    "correctAnswer": ["C"],
    "explanation": {
      "correct": "You can change an instance's machine type by stopping it, changing the type with gcloud or console, and restarting. Combined with Cloud Scheduler, this allows automated daily resizing to match business hour demands while minimizing off-hour costs.",
      "incorrect": {
        "A": "Committed use discounts save money but don't allow for dynamic resizing. You'd pay for the larger capacity 24/7.",
        "B": "Swapping instance templates requires recreating instances, losing local data and state. Direct machine type changes preserve data.",
        "D": "MIGs are for multiple instances. The question implies a single VM. Autoscaling in MIGs also doesn't resize existing instances."
      }
    },
    "keyConceptName": "Instance Resizing and Scheduling",
    "keyConcept": "Change instance machine types by stopping, modifying, and restarting. Automate with Cloud Scheduler for time-based capacity changes. This optimizes costs for workloads with predictable demand patterns while preserving disk data.",
    "tags": ["compute-engine", "resizing", "cost-optimization", "scheduling"],
    "examPatternKeywords": [
      "during business hours",
      "optimize costs",
      "minimal resources"
    ],
    "relatedQuestionIds": ["ace-compute-006", "ace-compute-014"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instances/changing-machine-type-of-stopped-instance"
  },

  {
    "id": "ace-compute-014",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "You are running a non-production batch processing workload on a Compute Engine Instance Group that can tolerate interruptions and needs to be highly cost-effective.",
    "question": "Which type of Compute Engine VM should you use to minimize the cost of the running instances?",
    "options": [
      {
        "id": "A",
        "text": "Standard VMs with Sustained Use Discounts"
      },
      {
        "id": "B",
        "text": "Custom Machine Type VMs"
      },
      {
        "id": "C",
        "text": "Preemptible VMs (Spot VMs)"
      },
      {
        "id": "D",
        "text": "Sole-Tenant Nodes"
      }
    ],
    "correctAnswer": ["C"],
    "explanation": {
      "correct": "Preemptible VMs (now called Spot VMs) are significantly cheaper than standard VMs but can be stopped (preempted) by Google Cloud with a 30-second warning. They are ideal for fault-tolerant, non-critical, or batch processing workloads, offering the lowest cost.",
      "incorrect": {
        "A": "Sustained Use Discounts apply to standard VMs running for a large portion of the month, but they are still more expensive than Spot VMs.",
        "B": "Custom Machine Types help optimize resource fit but do not inherently offer a significant cost reduction like Spot VMs.",
        "D": "Sole-Tenant Nodes are for regulatory or licensing requirements and are much more expensive than standard VMs."
      }
    },
    "keyConceptName": "Compute Engine Cost Optimization",
    "keyConcept": "Preemptible/Spot VMs are the primary mechanism for maximizing cost savings on Compute Engine for non-critical, fault-tolerant workloads by leveraging unused GCP capacity.",
    "tags": [
      "compute-engine",
      "cost-optimization",
      "preemptible-vms",
      "spot-vms"
    ],
    "examPatternKeywords": [
      "minimize the cost",
      "can tolerate interruptions",
      "non-production batch"
    ],
    "relatedQuestionIds": ["ace-compute-009"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instances/spot"
  },
  {
    "id": "ace-compute-015",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "You need to create a group of identical Compute Engine instances that will automatically scale based on CPU utilization and will be managed as a single unit.",
    "question": "Which Compute Engine resource is the correct choice to meet these requirements?",
    "options": [
      {
        "id": "A",
        "text": "Unmanaged Instance Group"
      },
      {
        "id": "B",
        "text": "Instance Template"
      },
      {
        "id": "C",
        "text": "Stateful Managed Instance Group (MIG)"
      },
      {
        "id": "D",
        "text": "Stateless Managed Instance Group (MIG)"
      }
    ],
    "correctAnswer": ["D"],
    "explanation": {
      "correct": "A **Stateless Managed Instance Group (MIG)** (D) is designed to run identical, stateless instances. It provides autoscaling (based on metrics like CPU), autohealing, and automatic updates/rollbacks, managing the instances as a single, scalable unit.",
      "incorrect": {
        "A": "Unmanaged Instance Groups do not support autoscaling or autohealing.",
        "B": "An Instance Template defines the configuration for a VM but is not a group, and it does not provide management features like autoscaling.",
        "C": "Stateful MIGs are used for applications that need to preserve disk, IP, and hostname across restarts/recreations and are generally not used for highly scalable, identical stateless groups."
      }
    },
    "keyConceptName": "Managed Instance Groups (MIGs)",
    "keyConcept": "MIGs are the core resource for building scalable, highly available, and auto-healing services on Compute Engine.",
    "tags": ["compute-engine", "autoscaling", "migs", "high-availability"],
    "examPatternKeywords": [
      "identical Compute Engine instances",
      "automatically scale",
      "managed as a single unit"
    ],
    "relatedQuestionIds": ["ace-compute-007"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instance-groups"
  },
  {
    "id": "ace-compute-016",
    "domain": "compute-engine",
    "difficulty": "easy",
    "type": "multiple-choice",
    "scenario": "You are creating a new Compute Engine VM and notice that the available predefined machine types do not exactly match your application's CPU and memory needs. You want to avoid overpaying for unused resources.",
    "question": "What is the most cost-effective solution for creating a VM with the precise amount of vCPU and memory required?",
    "options": [
      {
        "id": "A",
        "text": "Use a custom machine type."
      },
      {
        "id": "B",
        "text": "Choose the closest predefined N1 machine type."
      },
      {
        "id": "C",
        "text": "Use a machine type that is eligible for a committed use discount."
      },
      {
        "id": "D",
        "text": "Use a sole-tenant node."
      }
    ],
    "correctAnswer": ["A"],
    "explanation": {
      "correct": "Custom machine types allow you to specify the exact vCPU count and memory size (within certain constraints), ensuring you only pay for the resources your application needs, making it the most cost-effective option when predefined types don't fit.",
      "incorrect": {
        "B": "Choosing the closest predefined type will likely result in paying for more resources than needed (over-provisioning).",
        "C": "Committed Use Discounts (CUDs) reduce the rate, but the most cost-effective VM *configuration* is a custom type if resources are mismatched.",
        "D": "Sole-tenant nodes are expensive and used for specific licensing/security requirements, not for simple resource matching."
      }
    },
    "keyConceptName": "Custom Machine Types",
    "keyConcept": "Custom machine types provide granular control over vCPU and memory allocation, which is a powerful tool for cost optimization on Compute Engine.",
    "tags": ["compute-engine", "cost-optimization", "custom-machine-types"],
    "examPatternKeywords": [
      "precise amount of vCPU and memory",
      "avoid overpaying",
      "most cost-effective solution"
    ],
    "relatedQuestionIds": ["ace-compute-003"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type"
  },
  {
    "id": "ace-compute-017",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-select",
    "scenario": "You are deploying a critical 3-tier application using a Regional Managed Instance Group (MIG). You want to ensure the application is highly available and can automatically recover from common failures.",
    "question": "Which two features should be enabled on the Regional MIG to meet these requirements?",
    "options": [
      {
        "id": "A",
        "text": "Instance Template"
      },
      {
        "id": "B",
        "text": "Autoscaling"
      },
      {
        "id": "C",
        "text": "Autohealing"
      },
      {
        "id": "D",
        "text": "Regional Persistent Disk"
      },
      {
        "id": "E",
        "text": "Cross-region Load Balancing"
      }
    ],
    "correctAnswer": ["B", "C"],
    "explanation": {
      "correct": "A Regional MIG automatically distributes instances across multiple zones for high availability. To handle scaling and failures, you must enable **Autoscaling** (B) to ensure enough capacity under load, and **Autohealing** (C) (using a health check) to automatically recreate instances that fail to respond, thus ensuring application availability.",
      "incorrect": {
        "A": "An Instance Template is required to create a MIG, but it is not a feature you 'enable' to achieve HA/recovery.",
        "D": "Regional Persistent Disk is for stateful workloads; this is a stateless 3-tier application (implied by MIG usage).",
        "E": "Cross-region Load Balancing handles DR between regions, not HA within a region (which the Regional MIG already provides at the infrastructure level)."
      }
    },
    "keyConceptName": "MIG High Availability and Autohealing",
    "keyConcept": "Regional MIGs provide zonal HA. Autoscaling provides scaling HA (under load). Autohealing provides application HA (recovering from software failures).",
    "tags": [
      "compute-engine",
      "migs",
      "high-availability",
      "autohealing",
      "autoscaling"
    ],
    "examPatternKeywords": [
      "critical 3-tier application",
      "highly available",
      "automatically recover from common failures"
    ],
    "relatedQuestionIds": ["ace-compute-004"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instance-groups/creating-mig-with-autoscaling"
  },
  {
    "id": "ace-compute-018",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "You have a high-performance database running on a Compute Engine VM. The VM uses an attached Persistent Disk for its data. To protect against accidental deletion or corruption, you need to create a reliable, point-in-time backup of the disk.",
    "question": "What is the recommended, most common method for creating a point-in-time backup of a Persistent Disk?",
    "options": [
      {
        "id": "A",
        "text": "Creating a machine image of the running VM."
      },
      {
        "id": "B",
        "text": "Creating a disk snapshot."
      },
      {
        "id": "C",
        "text": "Detaching the disk and copying the raw data to Cloud Storage."
      },
      {
        "id": "D",
        "text": "Using the `gcloud compute disks resize` command."
      }
    ],
    "correctAnswer": ["B"],
    "explanation": {
      "correct": "Disk snapshots (B) are the native GCP feature for creating point-in-time, incremental backups of Persistent Disks. They are highly durable, global, and the most common method for backup and disaster recovery.",
      "incorrect": {
        "A": "A machine image captures the entire VM, including boot disk and configuration, which is overkill for just backing up the data disk.",
        "C": "Copying raw data to Cloud Storage is a manual and error-prone process that is not incremental or automated like snapshots.",
        "D": "Disk resize is for changing the size of the disk, not for backup."
      }
    },
    "keyConceptName": "Persistent Disk Snapshots",
    "keyConcept": "Snapshots provide a cost-effective, durable, and highly available mechanism for backing up and replicating Persistent Disk data across regions.",
    "tags": [
      "compute-engine",
      "persistent-disk",
      "backup",
      "snapshot",
      "disaster-recovery"
    ],
    "examPatternKeywords": [
      "reliable, point-in-time backup",
      "recommended, most common method"
    ],
    "relatedQuestionIds": ["ace-storage-003"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/disks/create-snapshots"
  },
  {
    "id": "ace-compute-019",
    "domain": "compute-engine",
    "difficulty": "hard",
    "type": "multiple-select",
    "scenario": "A financial services application needs to run on Compute Engine. Due to compliance and licensing requirements, the VMs must be physically isolated from other customers, and you need to maximize the cost savings for the committed, fixed resource requirement.",
    "question": "Which two Compute Engine features should you utilize?",
    "options": [
      {
        "id": "A",
        "text": "Sole-Tenant Nodes"
      },
      {
        "id": "B",
        "text": "Committed Use Discounts (CUDs)"
      },
      {
        "id": "C",
        "text": "Preemptible VMs (Spot VMs)"
      },
      {
        "id": "D",
        "text": "Custom Machine Types"
      },
      {
        "id": "E",
        "text": "Managed Instance Groups (MIGs)"
      }
    ],
    "correctAnswer": ["A", "B"],
    "explanation": {
      "correct": "Compliance requiring physical isolation is met by **Sole-Tenant Nodes** (A). These nodes are dedicated physical servers. To maximize cost savings for a **committed, fixed resource requirement**, **Committed Use Discounts (CUDs)** (B) are the most effective mechanism, as they provide a significant discount in exchange for a time commitment.",
      "incorrect": {
        "C": "Preemptible VMs/Spot VMs are for interruptible workloads and are not suitable for a 'fixed' requirement, nor do they guarantee physical isolation.",
        "D": "Custom Machine Types optimize resource fit, but CUDs offer a greater financial incentive for a long-term commitment.",
        "E": "MIGs are for scaling and availability, not licensing/isolation/committed costs."
      }
    },
    "keyConceptName": "Compute Engine Isolation and Commitment",
    "keyConcept": "Sole-Tenant Nodes are for physical isolation and dedicated hardware. CUDs are for maximizing savings on long-term, stable resource usage.",
    "tags": [
      "compute-engine",
      "cost-optimization",
      "security",
      "licensing",
      "sole-tenant-nodes",
      "cuds"
    ],
    "examPatternKeywords": [
      "physically isolated",
      "compliance",
      "maximize the cost savings",
      "committed, fixed resource"
    ],
    "relatedQuestionIds": ["ace-compute-003"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/sole-tenant-nodes"
  },
  {
    "id": "ace-compute-020",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "A development team is using a standard Compute Engine VM for continuous integration/continuous deployment (CI/CD) builds. They need to ensure that the VM has the correct IAM permissions to push images to a private Artifact Registry (formerly Container Registry) without managing any API keys or credentials.",
    "question": "What is the correct and most secure approach to grant the VM permission to push images?",
    "options": [
      {
        "id": "A",
        "text": "Generate a Service Account key and securely store it on the VM."
      },
      {
        "id": "B",
        "text": "Assign a custom Service Account to the VM and grant it the 'Artifact Registry Writer' role."
      },
      {
        "id": "C",
        "text": "Use the project's Default Compute Engine Service Account and grant it the 'Editor' role."
      },
      {
        "id": "D",
        "text": "Assign the 'Artifact Registry Writer' role to the user who created the VM."
      }
    ],
    "correctAnswer": ["B"],
    "explanation": {
      "correct": "The most secure and recommended approach is to assign a custom Service Account (following the principle of least privilege) to the VM instance (workload identity) and grant it the minimal required role, which is 'Artifact Registry Writer' (B). This avoids key management and utilizes instance-level credentials.",
      "incorrect": {
        "A": "Generating and storing keys (A) is a security risk and is not the recommended GCP practice.",
        "C": "Using the Default Compute Engine Service Account with the 'Editor' role (C) violates the principle of least privilege.",
        "D": "Granting the role to a user (D) will not grant the VM/CI process the permission it needs to authenticate as a machine."
      }
    },
    "keyConceptName": "Compute Engine Workload Identity",
    "keyConcept": "VMs should use an attached custom Service Account with the minimum required IAM permissions (least privilege) to interact with other GCP services.",
    "tags": [
      "compute-engine",
      "iam",
      "security",
      "service-accounts",
      "least-privilege"
    ],
    "examPatternKeywords": [
      "correct and most secure approach",
      "without managing any API keys"
    ],
    "relatedQuestionIds": ["ace-iam-003"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/access/create-enable-service-accounts-for-instances"
  },
  {
    "id": "ace-compute-021",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "You have a single-instance database running on Compute Engine that is stateful and cannot be easily recreated. You need to protect the instance and its data disk against accidental termination.",
    "question": "Which VM configuration option is the most effective way to prevent the instance from being accidentally stopped or deleted?",
    "options": [
      {
        "id": "A",
        "text": "Configure the VM to be a Regional Managed Instance Group (MIG) with a size of 1."
      },
      {
        "id": "B",
        "text": "Enable 'Deletion Protection' for the Compute Engine instance."
      },
      {
        "id": "C",
        "text": "Set the disk's auto-delete option to 'No'."
      },
      {
        "id": "D",
        "text": "Use a Cloud Monitoring alert to notify administrators of a pending deletion."
      }
    ],
    "correctAnswer": ["B"],
    "explanation": {
      "correct": "**Deletion Protection** (B) is a specific flag for Compute Engine VMs that prevents users from accidentally deleting the instance (and its associated boot disk) via the console or gcloud command, making it the most direct and effective measure.",
      "incorrect": {
        "A": "MIGs are designed for auto-healing and scaling stateless workloads, and a single instance MIG is not the primary way to prevent accidental deletion.",
        "C": "Setting the disk's auto-delete option (C) only prevents the disk from being deleted *if the instance is deleted*, but it does not prevent the instance deletion itself.",
        "D": "A monitoring alert (D) only notifies after the action is initiated, but it does not prevent the deletion."
      }
    },
    "keyConceptName": "Compute Engine Deletion Protection",
    "keyConcept": "Deletion Protection is a safeguard against accidental resource removal, a best practice for critical, stateful, or long-lived Compute Engine instances.",
    "tags": ["compute-engine", "security", "stateful", "best-practices"],
    "examPatternKeywords": [
      "stateful",
      "accidental termination",
      "most effective way to prevent"
    ],
    "relatedQuestionIds": ["ace-compute-007"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instances/prevent-deleting-instance"
  },
  {
    "id": "ace-compute-022",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "Your application runs on a Managed Instance Group (MIG) behind a Global HTTP(S) Load Balancer. You need to deploy a software update with zero downtime. The deployment must only proceed to the next instance once the health check passes on the newly updated instance.",
    "question": "Which MIG feature is specifically designed to handle this type of controlled, zero-downtime deployment?",
    "options": [
      {
        "id": "A",
        "text": "Autoscaling policies"
      },
      {
        "id": "B",
        "text": "Instance Template replacement"
      },
      {
        "id": "C",
        "text": "Proactive Instance Updater"
      },
      {
        "id": "D",
        "text": "Initial rollout of a new MIG"
      }
    ],
    "correctAnswer": ["C"],
    "explanation": {
      "correct": "The **Proactive Instance Updater** (C) is the key feature of a MIG that manages the rollout of new Instance Templates. It allows you to configure rolling updates (zero downtime) based on a configured health check, ensuring that traffic is only shifted to a new instance after the health check is successful.",
      "incorrect": {
        "A": "Autoscaling policies (A) deal with scaling up/down under load, not software updates.",
        "B": "Instance Template replacement (B) is the *action* of changing the template, but the Updater is the *process* that governs the rollout method (e.g., rolling update, canary).",
        "D": "Initial rollout (D) is not the correct term; it's the Updater that manages the change in a controlled way."
      }
    },
    "keyConceptName": "MIG Rolling Updates",
    "keyConcept": "MIGs support automated rolling updates, providing controlled, zero-downtime deployment for stateless applications.",
    "tags": [
      "compute-engine",
      "migs",
      "deployment",
      "zero-downtime",
      "rolling-update"
    ],
    "examPatternKeywords": [
      "zero downtime",
      "deploy a software update",
      "health check passes on the newly updated instance"
    ],
    "relatedQuestionIds": ["ace-app-008"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/instance-groups/rolling-out-updates-to-managed-instance-groups"
  },
  {
    "id": "ace-compute-023",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-select",
    "scenario": "You are migrating a critical, high-IOPS database from on-premises to a Compute Engine VM. The database requires a fast, low-latency disk that can withstand a zonal failure.",
    "question": "Which two Persistent Disk configurations meet these requirements?",
    "options": [
      {
        "id": "A",
        "text": "Zonal Balanced Persistent Disk"
      },
      {
        "id": "B",
        "text": "Zonal Standard Persistent Disk"
      },
      {
        "id": "C",
        "text": "Regional Standard Persistent Disk"
      },
      {
        "id": "D",
        "text": "Regional SSD Persistent Disk"
      },
      {
        "id": "E",
        "text": "Zonal SSD Persistent Disk"
      }
    ],
    "correctAnswer": ["D", "E"],
    "explanation": {
      "correct": "High-IOPS and fast disk means you need a Solid State Drive (SSD) based option: **Zonal SSD Persistent Disk** (E) or **Regional SSD Persistent Disk** (D). Zonal SSD is fast and low-latency, while Regional SSD offers zonal resilience (can withstand a zonal failure by replicating data to a secondary zone). Both are SSD-based.",
      "incorrect": {
        "A": "Balanced PDs offer a good balance but are not as fast as SSD PDs, especially for high-IOPS requirements.",
        "B": "Standard PDs (HDDs) are optimized for throughput, not IOPS, and are too slow.",
        "C": "Regional Standard PDs are too slow (HDD)."
      }
    },
    "keyConceptName": "Persistent Disk Types",
    "keyConcept": "For high-performance (IOPS), use SSD-based disks. For zonal resilience, use the Regional disk option.",
    "tags": [
      "compute-engine",
      "persistent-disk",
      "storage",
      "high-availability",
      "performance"
    ],
    "examPatternKeywords": [
      "critical, high-IOPS database",
      "fast, low-latency disk",
      "withstand a zonal failure"
    ],
    "relatedQuestionIds": ["ace-storage-003"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/disks/types"
  },
  {
    "id": "ace-compute-024",
    "domain": "compute-engine",
    "difficulty": "easy",
    "type": "multiple-choice",
    "scenario": "You need to quickly deploy a simple web server on a Compute Engine VM. You want to use a startup script to install the necessary software packages (Apache, PHP) immediately after the VM is created.",
    "question": "Where should you specify the location of the startup script for the Compute Engine VM?",
    "options": [
      {
        "id": "A",
        "text": "In the `gcloud compute firewall-rules create` command."
      },
      {
        "id": "B",
        "text": "In the `Metadata` section of the VM instance settings."
      },
      {
        "id": "C",
        "text": "In the `IAM & Admin` policy bindings."
      },
      {
        "id": "D",
        "text": "In a separate `startup.yaml` file uploaded to the project."
      }
    ],
    "correctAnswer": ["B"],
    "explanation": {
      "correct": "Startup scripts (and shutdown scripts) are specified within the **Metadata** section of the Compute Engine VM configuration, typically using the `startup-script` key.",
      "incorrect": {
        "A": "Firewall rules (A) are for network access, not instance configuration.",
        "C": "IAM policy bindings (C) are for access control.",
        "D": "While you can reference a script from Cloud Storage, the actual configuration that tells the VM *where* to find and *run* the script is set in the Metadata."
      }
    },
    "keyConceptName": "Compute Engine Metadata",
    "keyConcept": "Metadata is a key-value store used to pass configuration to a VM instance during creation, including startup scripts, SSH keys, and custom application data.",
    "tags": [
      "compute-engine",
      "configuration",
      "deployment",
      "metadata",
      "startup-script"
    ],
    "examPatternKeywords": [
      "quickly deploy",
      "startup script",
      "where should you specify"
    ],
    "relatedQuestionIds": ["ace-compute-004"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/startupscript"
  },
  {
    "id": "ace-compute-025",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "You have a high-traffic web application running on a Regional Managed Instance Group (MIG). You need to ensure the application remains highly responsive during traffic spikes.",
    "question": "What is the recommended scaling policy target for the MIG to ensure rapid horizontal scaling to maintain low latency?",
    "options": [
      {
        "id": "A",
        "text": "CPU utilization at 80%"
      },
      {
        "id": "B",
        "text": "HTTP Load Balancing serving capacity (target utilization)"
      },
      {
        "id": "C",
        "text": "Monitoring metric (e.g., custom latency metric)"
      },
      {
        "id": "D",
        "text": "Maximum connection count"
      }
    ],
    "correctAnswer": ["B"],
    "explanation": {
      "correct": "When a MIG is behind an HTTP(S) Load Balancer, the most responsive and efficient scaling signal is the **HTTP Load Balancing serving capacity** (Target Utilization or Requests per second/Utilization). This allows the load balancer itself to signal when more capacity is needed, ensuring minimal request queueing and the lowest latency.",
      "incorrect": {
        "A": "CPU utilization is a common but slower indicator; it only scales after the instance is already burdened.",
        "C": "Custom metrics can be used, but the native Load Balancing signal (B) is the most integrated and recommended for web services behind an HTTP(S) LB.",
        "D": "Maximum connection count is a less precise measure for overall responsiveness compared to load balancer utilization."
      }
    },
    "keyConceptName": "MIG Autoscaling Policies",
    "keyConcept": "Autoscaling should use the most relevant metric for the workload. For web applications behind an HTTP(S) load balancer, the load balancer's capacity metric is usually superior to CPU.",
    "tags": ["compute-engine", "autoscaling", "load-balancing", "performance"],
    "examPatternKeywords": [
      "high-traffic web application",
      "highly responsive",
      "rapid horizontal scaling"
    ],
    "relatedQuestionIds": ["ace-compute-004"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/autoscaler/scaling-mode-load-balancing"
  },
  {
    "id": "ace-compute-026",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-select",
    "scenario": "A compliance requirement states that all newly created Compute Engine VMs in a project must have a specific set of security tags and must utilize a specific, restricted custom machine type.",
    "question": "Which two methods should a Cloud Engineer use to enforce these policies across the entire project?",
    "options": [
      {
        "id": "A",
        "text": "Create an Instance Template and instruct developers to always use it."
      },
      {
        "id": "B",
        "text": "Implement an Organization Policy Constraint to restrict allowed machine types."
      },
      {
        "id": "C",
        "text": "Apply the desired tags to the Default Network Firewall Rules."
      },
      {
        "id": "D",
        "text": "Use Cloud Asset Inventory to audit non-compliant resources monthly."
      },
      {
        "id": "E",
        "text": "Implement an Organization Policy Constraint to enforce required network tags."
      }
    ],
    "correctAnswer": ["B", "E"],
    "explanation": {
      "correct": "To **enforce policies across the entire project** and prevent non-compliant resource creation, you must use **Organization Policy Constraints**. This includes constraints to **restrict allowed machine types** (B) and to **enforce required network tags** (E).",
      "incorrect": {
        "A": "Instructing developers is a procedural control, not an automated enforcement mechanism.",
        "C": "Applying tags to firewall rules (C) only makes the tags available for use; it doesn't enforce their presence on VMs.",
        "D": "Cloud Asset Inventory (D) is an audit tool that detects violations after they occur, not a proactive enforcement mechanism."
      }
    },
    "keyConceptName": "Organization Policy Service",
    "keyConcept": "Organization Policies are used to centrally control the configuration of cloud resources across the entire organization, folders, or projects, acting as a preventative guardrail.",
    "tags": [
      "iam",
      "security",
      "compliance",
      "organization-policy",
      "compute-engine"
    ],
    "examPatternKeywords": [
      "enforce these policies",
      "across the entire project",
      "restricted custom machine type"
    ],
    "relatedQuestionIds": ["ace-iam-008"],
    "officialDocsUrl": "https://cloud.google.com/resource-manager/docs/organization-policy/overview"
  },
  {
    "id": "ace-compute-027",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "Your Compute Engine VM runs a web service on port 8080. By default, no external traffic is allowed to reach the VM. You need to enable access to port 8080 from the public internet for all instances with the network tag 'web-frontend'.",
    "question": "How should you configure the networking for this access?",
    "options": [
      {
        "id": "A",
        "text": "Create an Egress Firewall rule with a target tag 'web-frontend' and destination port 8080."
      },
      {
        "id": "B",
        "text": "Create an Ingress Firewall rule with a target tag 'web-frontend', source IP range 0.0.0.0/0, and allow TCP port 8080."
      },
      {
        "id": "C",
        "text": "Configure a VPC Peering connection with a firewall rule to open port 8080."
      },
      {
        "id": "D",
        "text": "Modify the instance's network interface to allow all traffic on port 8080."
      }
    ],
    "correctAnswer": ["B"],
    "explanation": {
      "correct": "Traffic *coming into* the VM requires an **Ingress Firewall rule** (B). To allow access from the public internet, the **source IP range** must be **0.0.0.0/0**. The rule must target the VMs using the **target tag 'web-frontend'** and allow **TCP port 8080**.",
      "incorrect": {
        "A": "Egress (A) is for outgoing traffic, not incoming. Ingress is required.",
        "C": "VPC Peering (C) connects two internal networks, it does not open access to the public internet.",
        "D": "Network interface settings (D) do not override the default VPC firewall, which is the mechanism that blocks external traffic."
      }
    },
    "keyConceptName": "VPC Firewall Rules",
    "keyConcept": "VPC firewall rules control all network traffic to and from Compute Engine VMs and can be applied selectively using network tags.",
    "tags": ["compute-engine", "networking", "firewall-rules", "security"],
    "examPatternKeywords": [
      "enable access... from the public internet",
      "for all instances with the network tag"
    ],
    "relatedQuestionIds": ["ace-networking-002"],
    "officialDocsUrl": "https://cloud.google.com/vpc/docs/firewalls"
  },
  {
    "id": "ace-compute-028",
    "domain": "compute-engine",
    "difficulty": "medium",
    "type": "multiple-choice",
    "scenario": "A data processing job runs on a Compute Engine VM and saves results to a separate Persistent Disk. You want to detach the data disk from the running VM and attach it to a new VM in a different zone within the same region for a subsequent processing step.",
    "question": "What must you do to successfully move the disk between the two VMs?",
    "options": [
      {
        "id": "A",
        "text": "Create a disk image of the data disk and provision a new disk from the image in the new zone."
      },
      {
        "id": "B",
        "text": "Ensure the original VM is stopped, detach the zonal Persistent Disk, and then attach it to the new VM in the new zone."
      },
      {
        "id": "C",
        "text": "Create a disk snapshot, create a new disk from the snapshot in the new zone, and then attach it to the new VM."
      },
      {
        "id": "D",
        "text": "Detach the disk from the running VM, create a Regional Persistent Disk from it, and attach it to the new VM."
      }
    ],
    "correctAnswer": ["C"],
    "explanation": {
      "correct": "Zonal Persistent Disks are tied to their zone and cannot be moved directly to a new zone. To move data between zones, you must create a **disk snapshot** (which is a global resource) and then **create a new disk from the snapshot** (C) in the destination zone, then attach it to the new VM.",
      "incorrect": {
        "A": "Disk images are typically for boot disks; snapshots are better suited for point-in-time data disk movement.",
        "B": "This is impossible; you cannot attach a Zonal Persistent Disk to a VM in a different zone.",
        "D": "You cannot simply convert a Zonal PD to a Regional PD and change zones simultaneously; the snapshot/create-new-disk workflow is the correct way."
      }
    },
    "keyConceptName": "Persistent Disk Migration",
    "keyConcept": "Zonal resources (like Zonal PDs) must be replicated (via snapshots) to move their data to another zone or region.",
    "tags": ["compute-engine", "persistent-disk", "migration", "snapshot"],
    "examPatternKeywords": [
      "detach the data disk",
      "attach it to a new VM in a different zone",
      "must you do"
    ],
    "relatedQuestionIds": ["ace-compute-007"],
    "officialDocsUrl": "https://cloud.google.com/compute/docs/disks/create-snapshots"
  }
]
